{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "trafficsign.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nXeIirKzD8K",
        "colab_type": "code",
        "outputId": "a2294307-dcb1-42cf-f965-0ecb18875a37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UozCxtoB1QIE",
        "colab_type": "code",
        "outputId": "1dfc8708-309e-4b67-a665-3db46c0e6144",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd '/content/drive/My Drive/data1'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/data1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uT50_Ory_1Zt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "data = []\n",
        "labels = []\n",
        "classes = 3\n",
        "cur_path = os.getcwd()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_sBvzRjeCb5",
        "colab_type": "code",
        "outputId": "893a22ca-cb9d-45e1-bcb6-cb16a8757420",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "!pip install pyyaml h5py"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from h5py) (1.18.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hPQPV881XJ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Conv2D,MaxPool2D,Flatten\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing import image   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mAk2XG_3Zf2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "traindir='/content/drive/My Drive/data1/train'\n",
        "valdir='/content/drive/My Drive/data1/val'\n",
        "image = np.array(traindir)\n",
        "data.append(image)\n",
        "labels.append(classes)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9gQy6qLBvIE",
        "colab_type": "code",
        "outputId": "181fa5b9-3a75-498d-e033-3892a2a91559",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Converting lists into numpy arrays\n",
        "data = np.array(data)\n",
        "labels = np.array(labels)\n",
        "print(data.shape, labels.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1,) (1,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-1ZG-CR33jL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier = Sequential()\n",
        "\n",
        "# convolution layer - 32 feature detectors of 3x3 shape plus a rectifier on top of our convolved feature map\n",
        "classifier.add(Conv2D(32, (3,3), input_shape=(64, 64, 3), activation='relu'))\n",
        "\n",
        "# max pooling layer - of 2x2 shape\n",
        "classifier.add(MaxPool2D(pool_size=(2, 2)))\n",
        "\n",
        "# another convolution layer\n",
        "classifier.add(Conv2D(32, (3,3), activation='relu'))\n",
        "\n",
        "# another max pooling layer\n",
        "classifier.add(MaxPool2D(pool_size=(2, 2)))\n",
        "\n",
        "# flattening layer\n",
        "classifier.add(Flatten())\n",
        "\n",
        "# fully connected layer\n",
        "classifier.add(Dense(units=128, activation='relu'))\n",
        "\n",
        "# output layer\n",
        "classifier.add(Dense(units=3, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D47GeNQA3Fib",
        "colab_type": "code",
        "outputId": "6092a813-52dc-4112-b1ef-584120f8022b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                    shear_range=0.2,\n",
        "                                    zoom_range=0.2,\n",
        "                                    horizontal_flip=True)\n",
        "\n",
        "val_datagen = ImageDataGenerator( rescale=1./255)\n",
        "\n",
        "training_set = train_datagen.flow_from_directory(directory=traindir,\n",
        "                                                target_size=(64, 64),\n",
        "                                                batch_size=32,\n",
        "                                                class_mode='categorical'\n",
        "                                                )\n",
        "val_set = val_datagen.flow_from_directory(directory=valdir,\n",
        "                                              target_size=(64, 64),\n",
        "                                              batch_size=32,\n",
        "                                              class_mode='categorical')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 330 images belonging to 3 classes.\n",
            "Found 4 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWWMgDqA53OS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngg70PQEndPz",
        "colab_type": "code",
        "outputId": "69c427ec-893f-4ffb-9b4a-798f6fe99d51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "import os\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "filepath = \"/content/drive/My Drive/data/saved/weights-improvement-{epoch:02d}-{loss: .4f}.hdf5\"\n",
        "checkpoint_dir = os.path.dirname(filepath)\n",
        "\n",
        "# Create a callback that saves the model's weights\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]\n",
        "history=classifier.fit_generator(training_set,\n",
        "                         steps_per_epoch=10,                         \n",
        "                         epochs=5,                                 \n",
        "                         validation_data=val_set,\n",
        "                         validation_steps=2500,                         \n",
        "                         callbacks=callbacks_list)   "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "10/10 [==============================] - 252s 25s/step - loss: 0.0950 - accuracy: 0.9966 - val_loss: 15.3405 - val_accuracy: 0.2500\n",
            "\n",
            "Epoch 00001: loss improved from inf to 0.09283, saving model to /content/drive/My Drive/data/saved/weights-improvement-01- 0.0928.hdf5\n",
            "Epoch 2/5\n",
            "10/10 [==============================] - 252s 25s/step - loss: 0.0827 - accuracy: 0.9875 - val_loss: 15.1020 - val_accuracy: 0.2500\n",
            "\n",
            "Epoch 00002: loss improved from 0.09283 to 0.08266, saving model to /content/drive/My Drive/data/saved/weights-improvement-02- 0.0827.hdf5\n",
            "Epoch 3/5\n",
            "10/10 [==============================] - 252s 25s/step - loss: 0.0490 - accuracy: 0.9964 - val_loss: 14.9094 - val_accuracy: 0.2500\n",
            "\n",
            "Epoch 00003: loss improved from 0.08266 to 0.05030, saving model to /content/drive/My Drive/data/saved/weights-improvement-03- 0.0503.hdf5\n",
            "Epoch 4/5\n",
            "10/10 [==============================] - 252s 25s/step - loss: 0.0241 - accuracy: 1.0000 - val_loss: 16.4444 - val_accuracy: 0.2500\n",
            "\n",
            "Epoch 00004: loss improved from 0.05030 to 0.02461, saving model to /content/drive/My Drive/data/saved/weights-improvement-04- 0.0246.hdf5\n",
            "Epoch 5/5\n",
            "10/10 [==============================] - 252s 25s/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 16.3446 - val_accuracy: 0.2500\n",
            "\n",
            "Epoch 00005: loss improved from 0.02461 to 0.00983, saving model to /content/drive/My Drive/data/saved/weights-improvement-05- 0.0098.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khCE-uQoT6je",
        "colab_type": "code",
        "outputId": "38785d5c-f6bb-4986-df5a-c9722393c672",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "source": [
        "training_set.class_indices\n",
        "classifier.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 62, 62, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 31, 31, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 29, 29, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               802944    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 387       \n",
            "=================================================================\n",
            "Total params: 813,475\n",
            "Trainable params: 813,475\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-j1sHqdEO3js",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "new=classifier.predict(val_set)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1556gS4ty_b",
        "colab_type": "code",
        "outputId": "b48e536d-258e-415d-d7f9-7a78d8419e3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "\n",
        "test_steps_per_epoch = np.math.ceil(val_set.samples / val_set.batch_size)\n",
        "\n",
        "predictions = classifier.predict_generator(val_set, steps=test_steps_per_epoch)\n",
        "print(predictions)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[9.9049117e-03 9.9009502e-01 4.2966897e-13]\n",
            " [9.9999094e-01 9.0126450e-06 2.0999268e-10]\n",
            " [1.0000000e+00 1.5275727e-10 4.6295728e-12]\n",
            " [9.9999940e-01 6.1577919e-07 1.2761465e-10]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFoBgpraMlBb",
        "colab_type": "code",
        "outputId": "a4e79c88-0b90-4d70-8d74-f11f635cfac2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Evaluate the restored model\n",
        "loss, acc = classifier.evaluate(training_set, verbose=2)\n",
        "print(loss,acc)\n",
        "loss1, acc1 = classifier.evaluate(val_set, verbose=2)\n",
        "print(loss1,acc1)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0011405833065509796 1.0\n",
            "16.344579696655273 0.25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3iYhTe3UGsQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def test_unseen(filename):\n",
        "    test_image =  image.load_img(filename, target_size = (64, 64))\n",
        "    # converting to a 3D array\n",
        "    test_image = image.img_to_array(test_image)\n",
        "    test_image = np.expand_dims(test_image, axis=0)\n",
        "    result = classifier.predict(test_image)\n",
        "    \n",
        "    if result[0][0] == 1:\n",
        "        prediction = \"10\"\n",
        "    elif result[0][0] == 2:\n",
        "        prediction = \"20\"\n",
        "    else:\n",
        "        prediction = \"30\"\n",
        "        \n",
        "    return prediction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClOzprkhcGDw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "import glob\n",
        "\n",
        "path = '/content/drive/My Drive/data/val/'\n",
        "for infile in glob.glob( os.path.join(path, '*.jpg') ):\n",
        "   print(test_unseen(infile))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAZX869E7dTQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p saved_model\n",
        "classifier.save('/saved')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4NKIudvOCLf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}